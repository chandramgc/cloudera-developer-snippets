sqoop version

MySQL v5.0 and above offers very thorough coverage by Sqoop. Sqoop has been tested with mysql-connector-java-5.1.13-bin.jar.

copy mysql-connector-java to this location 
cp ./mysql-connector-java /opt/cloudera/parcels/CDH-5.13.1-1.cdh5.13.1.p0.2/lib/sqoop/lib/

sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568
sqoop list-databases \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568
sqoop list-tables \
	--connect jdbc:mysql://192.168.1.91:3306/mydb  \
	--username girish \
	--password Artha@568	
sqoop eval \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--query "SELECT * FROM customer LIMIT 10"
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer \
	--warehouse-dir /user/hduser/sqoop_import
	--delete-target-dir
	--num-mappers 3
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer_nopk \
	--warehouse-dir /user/hduser/sqoop_import \
	--num-mappers 1

#Things to remember for split-by
#Column should be indexed
#values in the field should be sparse
#also often it should be sequense generated or evenly incremented
#should not have null values


sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer_nopk \
	--warehouse-dir /user/hduser/sqoop_import \
	--split-by id

sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer_nopk \
	--warehouse-dir /user/hduser/sqoop_import \
	--split-by Name
	
sqoop import \
	-Dorg.apache.sqoop.slitter.allow_text_splitter=true	
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer_nopk \
	--warehouse-dir /user/hduser/sqoop_import \
	--split-by Name
	
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer \
	--warehouse-dir /user/hduser/sqoop_import \
	--boundary-query 'select min(id), max(id) from customer where id > 60'
	
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer \
	--num-mappers 2 \
	--warehouse-dir /user/hduser/sqoop_import \
	--boundary-query 'select 20, 30'
	
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer \
	--columns id,name \
	--num-mappers 2 \
	--warehouse-dir /user/hduser/sqoop_import \
	--boundary-query 'select 20, 30'

#--query 'SET @row_number =0; select @row_number:=@row_number+1 as number, state, count(id) count from customer group by state order by @row_number;' \	

# table and/or columns is mutually exclusive with query
# for query split-by is mandatory if num-mappers is greater than 1
# query should have a placeholder \$CONDITIONS

sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--num-mappers 2 \
	--target-dir /user/hduser/sqoop_import/customer_query \
	--query "SELECT Id, Name, State FROM mydb.customer   where State = 'Utah' and \$CONDITIONS " \
	--split-by Id
	
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table customer_nopk \
	--warehouse-dir /user/hduser/sqoop_import \
	--autoreset-to-one-mappers

sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table employees \
	--warehouse-dir /user/hduser/sqoop_import 

sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--table employees \
	--warehouse-dir /user/hduser/sqoop_import \
	--delete-target-dir \
	--null-non-string -1 \
	--fields-terminated-by "\t" \
	--lines-terminated-by ":" 
	
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/mydb \
	--username girish \
	--password Artha@568 \
	--num-mappers 1 \
	--table employees \
	--warehouse-dir /user/hduser/sqoop_import \
	--delete-target-dir \
	--null-non-string -1 \
	--fields-terminated-by "\000" \
	--lines-terminated-by ":" 

sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--num-mappers 2 \
	--target-dir /user/hduser/sqoop_import/retail_db/orders \
	--query "SELECT * FROM order where \$CONDITIONS and order_date like '2013-%' " \
	--split-by order_Id
	--append

sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--num-mappers 2 \
	--target-dir /user/hduser/sqoop_import/retail_db/orders \
	--table orders \
	--where "order_date like '2014-1%'"\
	--append

sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--num-mappers 2 \
	--target-dir /user/hduser/sqoop_import/retail_db/orders \
	--table orders \
	--check-column order_date \
	--incremental append \
	--last-value '2014-02-28' 
	
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--num-mappers 2 \
	--table orders \
	--hive-import \
	--hive-databases dgadiraju_sqoop_import \
	--hive-table order_items 
	
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--num-mappers 2 \
	--table orders \
	--hive-import \
	--hive-databases dgadiraju_sqoop_import \
	--hive-overwrite \
	--hive-table order_items

#Note: create-hive-table will not create hive table. But it will throws a error if table
#already exists
#Note: Before loading into hive table it will load into staging table location (/user/girish/order_items)
#In this location, staging files will be created these files should be removed else it will throws error if we run the hive command next time
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--num-mappers 2 \
	--table orders \
	--hive-import \
	--hive-databases dgadiraju_sqoop_import \
	--create-hive-table \
	--hive-table order_items
	
sqoop import \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--num-mappers 2 \
	--warehouse-dir /user/hduser/sqoop_import/retail_db \
	--autoreset-to-one-mapper
	
sqoop export \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--export-dir /user/hduser/sqoop_import/retail_db \
	--input-fields-terminated-by "\001" \
	--table daily_revenes \
	--columns order_date, revenue \
	--num-mappers 2 
	
#Note: update-key is used to update rows form hive to relational database. update-key should be the primary key (optional)
#It only update the data but not inserts
sqoop export \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--export-dir /user/hduser/sqoop_import/retail_db \
	--input-fields-terminated-by "\001" \
	--table daily_revenes \
	--update-key order_date \
	--num-mappers 2 
	
#Note: It will allow update and inserts
sqoop export \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--export-dir /user/hduser/sqoop_import/retail_db \
	--input-fields-terminated-by "\001" \
	--table daily_revenes \
	--update-key order_date \
	--update-mode allowinsert \
	--num-mappers 2 
	
#Note: When we export records on multi-threading if 1 thread fails to load data it will not affect other thread this my leave table in consistent state mean copy partial data to avoid this we use staging-table
#staging-table should be empty
sqoop export \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--export-dir /user/hduser/sqoop_import/retail_db \
	--input-fields-terminated-by "\001" \
	--table daily_revenes \
	--staging-table daily_revenes_stage \
	--num-mappers 4 
	
sqoop export \
	--connect jdbc:mysql://192.168.1.91:3306/retail_db \
	--username ratail_user \
	--password Artha@568 \
	--export-dir /user/hduser/sqoop_import/retail_db \
	--input-fields-terminated-by "\001" \
	--table daily_revenes \
	--staging-table daily_revenes_stage \
	--clear-staging-table \
	--num-mappers 4 
	

	
	


